{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from badlands.model import Model as badlandsModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cargar el modelo\n",
    "model = badlandsModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Definir el archivo XML (ajusta el nombre si está en otra carpeta)\n",
    "model.load_xml('input_forced_out.xml')\n",
    "model.run_to_time(20000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2365023, 1)\n",
      "Valores válidos leídos: 2365023 min,max =  -100.0 15900.0\n",
      "Celdas DEM: 2365023\n",
      "Guardado: stepMapOficial.csv (len=2365023)\n",
      "Uplift (min,max) -> 5e-05 0.0015\n"
     ]
    }
   ],
   "source": [
    "# transformar_uplift_precip.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Configuración ---\n",
    "input_csv = \"stepMapOff.csv\"    # tu archivo con valores -100..15900 (puede tener 1 o más columnas)\n",
    "dem_csv   = \"xyz.csv\"   # tu DEM original (x,y,elev) para asegurar tamaño/grilla\n",
    "# Rango deseado (ajusta según tu calibración)\n",
    "uplift_range = (0.00005, 0.0015)  # rango para uplift en m/año (ej: 0.05 mm/a -> 0.00005 m/a)\n",
    "\n",
    "# --- Leer input robustamente ---\n",
    "def read_any_csv(path):\n",
    "    # intenta detectar separador automáticamente\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep=None, engine=\"python\", header=None, comment=\"#\")\n",
    "    except Exception:\n",
    "        df = pd.read_csv(path, header=None)  # fallback\n",
    "    return df\n",
    "\n",
    "vals_df = read_any_csv(input_csv)\n",
    "print(\"Input shape:\", vals_df.shape)\n",
    "# si viene en una sola columna con strings \"100.0,-11119.0,-13495.0\", separarlo:\n",
    "if vals_df.shape[1] == 1 and vals_df.iloc[:,0].astype(str).str.contains(\",\").any():\n",
    "    # intenta split por coma y reconstruir\n",
    "    expanded = vals_df.iloc[:,0].str.split(\",\", expand=True)\n",
    "    vals_df = expanded.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# tomar la columna de interés: si hay >1 columna asumimos ultima = valor objetivo\n",
    "values = vals_df.iloc[:, -1].astype(float).dropna().values\n",
    "print(\"Valores válidos leídos:\", len(values), \"min,max = \", values.min(), values.max())\n",
    "\n",
    "# --- Leer DEM para tamaño de grilla ---\n",
    "dem = read_any_csv(dem_csv)\n",
    "# si DEM tiene 3 columnas x,y,elev (header None) su número de celdas es:\n",
    "if dem.shape[1] >= 3:\n",
    "    n_cells_dem = dem.shape[0]\n",
    "else:\n",
    "    # si dem está en formato grilla (ncols,nrows) no estándar, asume flatten length\n",
    "    n_cells_dem = dem.shape[0]\n",
    "print(\"Celdas DEM:\", n_cells_dem)\n",
    "\n",
    "# --- Función de reescalado lineal ---\n",
    "def rescale(arr, target_min, target_max):\n",
    "    a = np.array(arr, dtype=float)\n",
    "    a_min, a_max = np.nanmin(a), np.nanmax(a)\n",
    "    if a_max == a_min:\n",
    "        return np.full(a.shape, 0.5*(target_min+target_max))\n",
    "    scaled = (a - a_min) / (a_max - a_min)\n",
    "    return target_min + scaled * (target_max - target_min)\n",
    "\n",
    "# --- Generar archivo de uplift (una columna) ---\n",
    "# Opción A: si quieres derivar uplift a partir del gradiente del input (ej. si input es elev)\n",
    "# calculamos gradiente 1D y luego lo mapeamos a rango uplift_range\n",
    "if np.ptp(values) > 0 and len(values) == n_cells_dem:\n",
    "    # interpretamos values como elevacion flattened y estimamos diferencias finite-diff\n",
    "    diff = np.abs(np.diff(values, prepend=values[0]))\n",
    "    uplift_vals = rescale(diff, uplift_range[0], uplift_range[1])\n",
    "    uplift_flat = uplift_vals\n",
    "else:\n",
    "    # Caso general: reescala directamente el array a rango uplift\n",
    "    uplift_vals = rescale(values, uplift_range[0], uplift_range[1])\n",
    "    if len(uplift_vals) != n_cells_dem:\n",
    "        uplift_flat = np.interp(np.arange(n_cells_dem),\n",
    "                                np.linspace(0, n_cells_dem-1, num=len(uplift_vals)),\n",
    "                                uplift_vals)\n",
    "    else:\n",
    "        uplift_flat = uplift_vals\n",
    "\n",
    "pd.DataFrame(uplift_flat).to_csv(\"data/stepMapOficial.csv\", index=False, header=False)\n",
    "print(\"Guardado: stepMapOficial.csv (len={})\".format(len(uplift_flat)))\n",
    "\n",
    "# --- Sanity checks ---\n",
    "print(\"Uplift (min,max) ->\", np.nanmin(uplift_flat), np.nanmax(uplift_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(\"dem_resampled.asc\") as src:\n",
    "    array = src.read(1)\n",
    "    transform = src.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = np.where(array != -9999)\n",
    "xs, ys = rasterio.transform.xy(transform, rows, cols)\n",
    "elev = array[rows, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"x\": xs,\n",
    "    \"y\": ys,\n",
    "    \"elev\": elev\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dem1_100m.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dem1_100m.csv\", sep=\",\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df.columns) == 1:\n",
    "    df = df.iloc[:,0].str.split(\",\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dem1_100m.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dem1_100m.csv\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\",\", \" \")\n",
    "\n",
    "with open(\"dem_space_100m.txt\", \"w\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iniciando a programar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-971d548c53a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# --- Cargar modelo (solo parsea) ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbadlandsModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# --- Determinar tiempo inicial (usar model.tNow si existe, si no tomar model.input.tStart) ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/badlands/model.py\u001b[0m in \u001b[0;36mload_xml\u001b[0;34m(self, filename, verbose)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# later using _build_mesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Initialise carbonate evolution if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/badlands/model.py\u001b[0m in \u001b[0;36m_build_mesh\u001b[0;34m(self, filename, verbose)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstraTIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarbTIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         ) = buildMesh.construct_mesh(self.input, filename, verbose)\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaveSed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/badlands/simulation/buildMesh.py\u001b[0m in \u001b[0;36mconstruct_mesh\u001b[0;34m(input, filename, verbose)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# Compute Finite Volume parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mFVmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_FV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlGIDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" - FV mesh \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwalltime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/badlands/surface/FVmethod.py\u001b[0m in \u001b[0;36mconstruct_FV\u001b[0;34m(self, lGIDs, verbose)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Call finite volume function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FV_utils\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlGIDs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/badlands/surface/FVmethod.py\u001b[0m in \u001b[0;36m_FV_utils\u001b[0;34m(self, lGIDs, verbose)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Voronoi and simplices declaration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mTmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_circumcenters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmeshplex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m>=\u001b[0m \u001b[0;34m\"0.14.0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/meshplex/mesh_tri.py\u001b[0m in \u001b[0;36mcreate_edges\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx_hierarchy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx_hierarchy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0ma_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         assert numpy.all(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/meshplex/helpers.py\u001b[0m in \u001b[0;36munique_rows\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     )\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0ma_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0ma_unique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_unique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptional_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mergesort'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'quicksort'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Driver robusto para correr Badlands en saltos de 250 ka (compatible Python 3.5)\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from badlands.model import Model as badlandsModel\n",
    "\n",
    "# --- Parámetros de la corrida ---\n",
    "xml = \"input12.xml\"\n",
    "final_t = 20000000.0   # 20 Ma en años\n",
    "step   = 250000.0      # 250 ka en años\n",
    "\n",
    "# --- Cargar modelo (solo parsea) ---\n",
    "model = badlandsModel()\n",
    "model.load_xml(xml)\n",
    "\n",
    "# --- Determinar tiempo inicial (usar model.tNow si existe, si no tomar model.input.tStart) ---\n",
    "if hasattr(model, \"tNow\") and model.tNow is not None:\n",
    "    cur = float(model.tNow)\n",
    "else:\n",
    "    cur = float(getattr(model.input, \"tStart\", 0.0))\n",
    "\n",
    "print(\"Inicio de la corrida. Tiempo inicial (años):\", cur, \"  (%.3f Ma)\" % (cur / 1e6))\n",
    "print(\"Objetivo final (años):\", final_t, \"  (%.1f Ma)\" % (final_t / 1e6))\n",
    "print(\"Paso solicitado (años):\", step, \"  (%.0f ka)\" % (step / 1000.0))\n",
    "print(\"Salida escrita en (intento):\", getattr(model.input, \"outDir\", \"output\"))\n",
    "\n",
    "# función auxiliar para listar h5 en carpeta output/h5 (intenta varias rutas)\n",
    "def list_h5(outdir=None):\n",
    "    candidates = []\n",
    "    if outdir:\n",
    "        candidates.append(os.path.join(outdir, \"h5\"))\n",
    "        candidates.append(outdir)\n",
    "    # rutas habituales\n",
    "    candidates.extend([\"output/h5\", \"output_0/h5\", \"output/hdf5\", \"output\"])\n",
    "    found = []\n",
    "    for c in candidates:\n",
    "        if os.path.exists(c):\n",
    "            found.extend(glob.glob(os.path.join(c, \"*.hdf5\")))\n",
    "            found.extend(glob.glob(os.path.join(c, \"*.h5\")))\n",
    "    return sorted(found)\n",
    "\n",
    "# --- Loop controlador: llamar run_to_time con target absoluto (cur+step) ---\n",
    "try:\n",
    "    while cur < final_t:\n",
    "        target = min(final_t, cur + step)\n",
    "        t0 = time.time()\n",
    "        print(\"\\n[*] Ejecutando model.run_to_time({}) ...\".format(int(target)))\n",
    "        model.run_to_time(target)   # avanza desde donde quedó hasta 'target'\n",
    "        dt = time.time() - t0\n",
    "\n",
    "        # actualizar cur desde model.tNow (si está) o desde model.input.tNow si existiera\n",
    "        cur = getattr(model, \"tNow\", None)\n",
    "        if cur is None:\n",
    "            cur = getattr(model.input, \"tNow\", None)\n",
    "        if cur is None:\n",
    "            # si por alguna razón ambos son None, estimamos por 'target'\n",
    "            cur = target\n",
    "\n",
    "        print(\"  -> Llegado a tNow = {} años ({} Ma). Paso tardó {:.1f} s\".format(int(cur), cur/1e6, dt))\n",
    "\n",
    "        # listar archivos h5 para ver si se escribieron\n",
    "        h5list = list_h5(getattr(model.input, \"outDir\", None))\n",
    "        print(\"  -> archivos h5 encontrados (ej.):\", len(h5list))\n",
    "        if len(h5list) > 0:\n",
    "            # mostramos los últimos 3 si hay\n",
    "            for f in h5list[-3:]:\n",
    "                try:\n",
    "                    print(\"     -\", os.path.basename(f), \"size(MB)={:.1f}\".format(os.path.getsize(f)/1e6))\n",
    "                except:\n",
    "                    print(\"     -\", os.path.basename(f))\n",
    "        # seguir al siguiente paso\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n==> CORRIDA interrumpida por el usuario. Último tNow =\", getattr(model, \"tNow\", None))\n",
    "\n",
    "print(\"\\nScript finalizado. Tiempo final registrado model.tNow =\", getattr(model, \"tNow\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Ejecutando model.run_to_time(250000) ...\n",
      "   - Writing outputs (12.37 seconds; tNow = 0.0)\n",
      "tNow = 250000.0 (16.92 seconds)\n",
      "   - Writing outputs (6.70 seconds; tNow = 250000.0)\n",
      " -> Llegado a tNow = 250000 años (0.25 Ma)\n",
      "[*] Ejecutando model.run_to_time(500000) ...\n",
      "tNow = 500000.0 (2.85 seconds)\n",
      "   - Writing outputs (6.21 seconds; tNow = 500000.0)\n",
      " -> Llegado a tNow = 500000 años (0.50 Ma)\n",
      "[*] Ejecutando model.run_to_time(750000) ...\n",
      "tNow = 750000.0 (2.63 seconds)\n",
      "   - Writing outputs (5.94 seconds; tNow = 750000.0)\n",
      " -> Llegado a tNow = 750000 años (0.75 Ma)\n",
      "[*] Ejecutando model.run_to_time(1000000) ...\n",
      "tNow = 1000000.0 (2.62 seconds)\n",
      "   - Writing outputs (6.38 seconds; tNow = 1000000.0)\n",
      " -> Llegado a tNow = 1000000 años (1.00 Ma)\n",
      "[*] Ejecutando model.run_to_time(1250000) ...\n",
      "tNow = 1250000.0 (3.86 seconds)\n",
      "   - Writing outputs (6.19 seconds; tNow = 1250000.0)\n",
      " -> Llegado a tNow = 1250000 años (1.25 Ma)\n",
      "[*] Ejecutando model.run_to_time(1500000) ...\n",
      "tNow = 1500000.0 (2.88 seconds)\n",
      "   - Writing outputs (6.08 seconds; tNow = 1500000.0)\n",
      " -> Llegado a tNow = 1500000 años (1.50 Ma)\n",
      "[*] Ejecutando model.run_to_time(1750000) ...\n",
      "tNow = 1750000.0 (2.82 seconds)\n",
      "   - Writing outputs (6.26 seconds; tNow = 1750000.0)\n",
      " -> Llegado a tNow = 1750000 años (1.75 Ma)\n",
      "[*] Ejecutando model.run_to_time(2000000) ...\n",
      "tNow = 2000000.0 (3.51 seconds)\n",
      "   - Writing outputs (7.16 seconds; tNow = 2000000.0)\n",
      " -> Llegado a tNow = 2000000 años (2.00 Ma)\n",
      "[*] Ejecutando model.run_to_time(2250000) ...\n",
      "tNow = 2250000.0 (2.64 seconds)\n",
      "   - Writing outputs (7.24 seconds; tNow = 2250000.0)\n",
      " -> Llegado a tNow = 2250000 años (2.25 Ma)\n",
      "[*] Ejecutando model.run_to_time(2500000) ...\n",
      "tNow = 2500000.0 (2.91 seconds)\n",
      "   - Writing outputs (6.84 seconds; tNow = 2500000.0)\n",
      " -> Llegado a tNow = 2500000 años (2.50 Ma)\n",
      "[*] Ejecutando model.run_to_time(2750000) ...\n",
      "tNow = 2750000.0 (3.36 seconds)\n",
      "   - Writing outputs (6.87 seconds; tNow = 2750000.0)\n",
      " -> Llegado a tNow = 2750000 años (2.75 Ma)\n",
      "[*] Ejecutando model.run_to_time(3000000) ...\n",
      "tNow = 3000000.0 (3.00 seconds)\n",
      "   - Writing outputs (6.60 seconds; tNow = 3000000.0)\n",
      " -> Llegado a tNow = 3000000 años (3.00 Ma)\n",
      "[*] Ejecutando model.run_to_time(3250000) ...\n",
      "tNow = 3250000.0 (3.26 seconds)\n",
      "   - Writing outputs (6.39 seconds; tNow = 3250000.0)\n",
      " -> Llegado a tNow = 3250000 años (3.25 Ma)\n",
      "[*] Ejecutando model.run_to_time(3500000) ...\n",
      "tNow = 3500000.0 (3.13 seconds)\n",
      "   - Writing outputs (6.48 seconds; tNow = 3500000.0)\n",
      " -> Llegado a tNow = 3500000 años (3.50 Ma)\n",
      "[*] Ejecutando model.run_to_time(3750000) ...\n",
      "tNow = 3750000.0 (3.82 seconds)\n",
      "   - Writing outputs (10.65 seconds; tNow = 3750000.0)\n",
      " -> Llegado a tNow = 3750000 años (3.75 Ma)\n",
      "[*] Ejecutando model.run_to_time(4000000) ...\n",
      "tNow = 4000000.0 (5.06 seconds)\n",
      "   - Writing outputs (7.64 seconds; tNow = 4000000.0)\n",
      " -> Llegado a tNow = 4000000 años (4.00 Ma)\n",
      "[*] Ejecutando model.run_to_time(4250000) ...\n",
      "tNow = 4250000.0 (2.76 seconds)\n",
      "   - Writing outputs (6.63 seconds; tNow = 4250000.0)\n",
      " -> Llegado a tNow = 4250000 años (4.25 Ma)\n",
      "[*] Ejecutando model.run_to_time(4500000) ...\n",
      "tNow = 4500000.0 (3.03 seconds)\n",
      "   - Writing outputs (7.50 seconds; tNow = 4500000.0)\n",
      " -> Llegado a tNow = 4500000 años (4.50 Ma)\n",
      "[*] Ejecutando model.run_to_time(4750000) ...\n",
      "tNow = 4750000.0 (3.17 seconds)\n",
      "   - Writing outputs (6.68 seconds; tNow = 4750000.0)\n",
      " -> Llegado a tNow = 4750000 años (4.75 Ma)\n",
      "[*] Ejecutando model.run_to_time(5000000) ...\n",
      "tNow = 5000000.0 (2.79 seconds)\n",
      "   - Writing outputs (6.52 seconds; tNow = 5000000.0)\n",
      " -> Llegado a tNow = 5000000 años (5.00 Ma)\n",
      "[*] Ejecutando model.run_to_time(5250000) ...\n",
      "tNow = 5250000.0 (2.87 seconds)\n",
      "   - Writing outputs (6.39 seconds; tNow = 5250000.0)\n",
      " -> Llegado a tNow = 5250000 años (5.25 Ma)\n",
      "[*] Ejecutando model.run_to_time(5500000) ...\n",
      "tNow = 5500000.0 (2.88 seconds)\n",
      "   - Writing outputs (6.55 seconds; tNow = 5500000.0)\n",
      " -> Llegado a tNow = 5500000 años (5.50 Ma)\n",
      "[*] Ejecutando model.run_to_time(5750000) ...\n",
      "tNow = 5750000.0 (3.05 seconds)\n",
      "   - Writing outputs (6.96 seconds; tNow = 5750000.0)\n",
      " -> Llegado a tNow = 5750000 años (5.75 Ma)\n",
      "[*] Ejecutando model.run_to_time(6000000) ...\n",
      "tNow = 6000000.0 (3.24 seconds)\n",
      "   - Writing outputs (6.54 seconds; tNow = 6000000.0)\n",
      " -> Llegado a tNow = 6000000 años (6.00 Ma)\n",
      "[*] Ejecutando model.run_to_time(6250000) ...\n",
      "tNow = 6250000.0 (2.79 seconds)\n",
      "   - Writing outputs (6.09 seconds; tNow = 6250000.0)\n",
      " -> Llegado a tNow = 6250000 años (6.25 Ma)\n",
      "[*] Ejecutando model.run_to_time(6500000) ...\n",
      "tNow = 6500000.0 (3.51 seconds)\n",
      "   - Writing outputs (6.06 seconds; tNow = 6500000.0)\n",
      " -> Llegado a tNow = 6500000 años (6.50 Ma)\n",
      "[*] Ejecutando model.run_to_time(6750000) ...\n",
      "tNow = 6750000.0 (2.71 seconds)\n",
      "   - Writing outputs (6.20 seconds; tNow = 6750000.0)\n",
      " -> Llegado a tNow = 6750000 años (6.75 Ma)\n",
      "[*] Ejecutando model.run_to_time(7000000) ...\n",
      "tNow = 7000000.0 (2.67 seconds)\n",
      "   - Writing outputs (6.09 seconds; tNow = 7000000.0)\n",
      " -> Llegado a tNow = 7000000 años (7.00 Ma)\n",
      "[*] Ejecutando model.run_to_time(7250000) ...\n",
      "tNow = 7250000.0 (2.70 seconds)\n",
      "   - Writing outputs (7.28 seconds; tNow = 7250000.0)\n",
      " -> Llegado a tNow = 7250000 años (7.25 Ma)\n",
      "[*] Ejecutando model.run_to_time(7500000) ...\n",
      "tNow = 7500000.0 (2.86 seconds)\n",
      "   - Writing outputs (6.17 seconds; tNow = 7500000.0)\n",
      " -> Llegado a tNow = 7500000 años (7.50 Ma)\n",
      "[*] Ejecutando model.run_to_time(7750000) ...\n",
      "tNow = 7750000.0 (2.72 seconds)\n",
      "   - Writing outputs (6.77 seconds; tNow = 7750000.0)\n",
      " -> Llegado a tNow = 7750000 años (7.75 Ma)\n",
      "[*] Ejecutando model.run_to_time(8000000) ...\n",
      "tNow = 8000000.0 (4.37 seconds)\n",
      "   - Writing outputs (7.70 seconds; tNow = 8000000.0)\n",
      " -> Llegado a tNow = 8000000 años (8.00 Ma)\n",
      "[*] Ejecutando model.run_to_time(8250000) ...\n",
      "tNow = 8250000.0 (2.80 seconds)\n",
      "   - Writing outputs (6.07 seconds; tNow = 8250000.0)\n",
      " -> Llegado a tNow = 8250000 años (8.25 Ma)\n",
      "[*] Ejecutando model.run_to_time(8500000) ...\n",
      "tNow = 8500000.0 (2.59 seconds)\n",
      "   - Writing outputs (5.93 seconds; tNow = 8500000.0)\n",
      " -> Llegado a tNow = 8500000 años (8.50 Ma)\n",
      "[*] Ejecutando model.run_to_time(8750000) ...\n",
      "tNow = 8750000.0 (2.72 seconds)\n",
      "   - Writing outputs (6.09 seconds; tNow = 8750000.0)\n",
      " -> Llegado a tNow = 8750000 años (8.75 Ma)\n",
      "[*] Ejecutando model.run_to_time(9000000) ...\n",
      "tNow = 9000000.0 (2.94 seconds)\n",
      "   - Writing outputs (6.21 seconds; tNow = 9000000.0)\n",
      " -> Llegado a tNow = 9000000 años (9.00 Ma)\n",
      "[*] Ejecutando model.run_to_time(9250000) ...\n",
      "tNow = 9250000.0 (2.74 seconds)\n",
      "   - Writing outputs (5.92 seconds; tNow = 9250000.0)\n",
      " -> Llegado a tNow = 9250000 años (9.25 Ma)\n",
      "[*] Ejecutando model.run_to_time(9500000) ...\n",
      "tNow = 9500000.0 (2.85 seconds)\n",
      "   - Writing outputs (6.05 seconds; tNow = 9500000.0)\n",
      " -> Llegado a tNow = 9500000 años (9.50 Ma)\n",
      "[*] Ejecutando model.run_to_time(9750000) ...\n",
      "tNow = 9750000.0 (2.74 seconds)\n",
      "   - Writing outputs (5.99 seconds; tNow = 9750000.0)\n",
      " -> Llegado a tNow = 9750000 años (9.75 Ma)\n",
      "[*] Ejecutando model.run_to_time(10000000) ...\n",
      "tNow = 10000000.0 (2.68 seconds)\n",
      "   - Writing outputs (6.07 seconds; tNow = 10000000.0)\n",
      " -> Llegado a tNow = 10000000 años (10.00 Ma)\n",
      "[*] Ejecutando model.run_to_time(10250000) ...\n",
      "tNow = 10250000.0 (2.66 seconds)\n",
      "   - Writing outputs (6.04 seconds; tNow = 10250000.0)\n",
      " -> Llegado a tNow = 10250000 años (10.25 Ma)\n",
      "[*] Ejecutando model.run_to_time(10500000) ...\n",
      "tNow = 10500000.0 (2.72 seconds)\n",
      "   - Writing outputs (6.45 seconds; tNow = 10500000.0)\n",
      " -> Llegado a tNow = 10500000 años (10.50 Ma)\n",
      "[*] Ejecutando model.run_to_time(10750000) ...\n",
      "tNow = 10750000.0 (2.66 seconds)\n",
      "   - Writing outputs (6.10 seconds; tNow = 10750000.0)\n",
      " -> Llegado a tNow = 10750000 años (10.75 Ma)\n",
      "[*] Ejecutando model.run_to_time(11000000) ...\n",
      "tNow = 11000000.0 (2.70 seconds)\n",
      "   - Writing outputs (6.25 seconds; tNow = 11000000.0)\n",
      " -> Llegado a tNow = 11000000 años (11.00 Ma)\n",
      "[*] Ejecutando model.run_to_time(11250000) ...\n",
      "tNow = 11250000.0 (2.92 seconds)\n",
      "   - Writing outputs (6.94 seconds; tNow = 11250000.0)\n",
      " -> Llegado a tNow = 11250000 años (11.25 Ma)\n",
      "[*] Ejecutando model.run_to_time(11500000) ...\n",
      "tNow = 11500000.0 (2.97 seconds)\n",
      "   - Writing outputs (6.80 seconds; tNow = 11500000.0)\n",
      " -> Llegado a tNow = 11500000 años (11.50 Ma)\n",
      "[*] Ejecutando model.run_to_time(11750000) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tNow = 11750000.0 (2.97 seconds)\n",
      "   - Writing outputs (6.86 seconds; tNow = 11750000.0)\n",
      " -> Llegado a tNow = 11750000 años (11.75 Ma)\n",
      "[*] Ejecutando model.run_to_time(12000000) ...\n",
      "tNow = 12000000.0 (2.81 seconds)\n",
      "   - Writing outputs (6.13 seconds; tNow = 12000000.0)\n",
      " -> Llegado a tNow = 12000000 años (12.00 Ma)\n",
      "[*] Ejecutando model.run_to_time(12250000) ...\n",
      "tNow = 12250000.0 (3.13 seconds)\n",
      "   - Writing outputs (6.95 seconds; tNow = 12250000.0)\n",
      " -> Llegado a tNow = 12250000 años (12.25 Ma)\n",
      "[*] Ejecutando model.run_to_time(12500000) ...\n",
      "tNow = 12500000.0 (3.71 seconds)\n",
      "   - Writing outputs (6.96 seconds; tNow = 12500000.0)\n",
      " -> Llegado a tNow = 12500000 años (12.50 Ma)\n",
      "[*] Ejecutando model.run_to_time(12750000) ...\n",
      "tNow = 12750000.0 (3.55 seconds)\n"
     ]
    }
   ],
   "source": [
    "from badlands.model import Model\n",
    "import time\n",
    "\n",
    "model = Model()\n",
    "model.load_xml(\"input12.xml\")\n",
    "\n",
    "cur = model.tNow if model.tNow is not None else model.input.tStart\n",
    "final_t = 20000000.0\n",
    "step = 250000.0\n",
    "\n",
    "while cur < final_t:\n",
    "    target = min(final_t, cur + step)\n",
    "    print(\"[*] Ejecutando model.run_to_time({}) ...\".format(int(target)))\n",
    "    model.run_to_time(target)\n",
    "    cur = model.tNow if model.tNow is not None else target\n",
    "    print(\" -> Llegado a tNow = {} años ({:.2f} Ma)\".format(int(cur), cur / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modificar_intervals.py\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "\n",
    "xml_in = \"input12.xml\"\n",
    "xml_out = \"input_forced_out.xml\"\n",
    "backup = \"input_backup.xml\"\n",
    "\n",
    "# copia de seguridad\n",
    "shutil.copyfile(xml_in, backup)\n",
    "print(\"Backup creado:\", backup)\n",
    "\n",
    "tree = ET.parse(xml_in)\n",
    "root = tree.getroot()\n",
    "\n",
    "dt_output = \"250000\"  # 250 ka\n",
    "\n",
    "changed = []\n",
    "\n",
    "for elem in root.iter():\n",
    "    taglow = elem.tag.lower()\n",
    "    # Si el nodo tiene atributo 'interval' lo forzamos\n",
    "    if 'interval' in elem.attrib:\n",
    "        old = elem.attrib.get('interval')\n",
    "        elem.set('interval', dt_output)\n",
    "        changed.append((elem.tag, 'interval', old, dt_output))\n",
    "    # Si el tag incluye 'timeseries' o 'timeSeries' o 'series' lo ajustamos o lo desactivamos\n",
    "    if 'timeseries' in taglow or 'timeseries' in elem.tag.lower() or 'time' in taglow and 'series' in taglow:\n",
    "        # intentamos forzar su intervalo si existe\n",
    "        if 'interval' in elem.attrib:\n",
    "            old = elem.attrib.get('interval')\n",
    "            elem.set('interval', dt_output)\n",
    "            changed.append((elem.tag, 'interval', old, dt_output))\n",
    "        else:\n",
    "            # si no tiene interval, agregamos un atributo interval con valor grande para evitar salidas frecuentes\n",
    "            elem.set('interval', dt_output)\n",
    "            changed.append((elem.tag, 'interval', None, dt_output))\n",
    "\n",
    "# Escribir nuevo XML\n",
    "tree.write(xml_out)\n",
    "print(\"XML modificado escrito en:\", xml_out)\n",
    "print(\"Cambios realizados:\")\n",
    "for c in changed:\n",
    "    print(\" - Tag {} attribute {}: {} -> {}\".format(*c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARREGLA ENCABEZADO Y COMAS POR ESPACIO EN EL CSV \n",
    "\n",
    "with open(\"data/uplift_step_interpolated_1D.csv\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Reemplazar comas por espacios\n",
    "text = text.replace(\",\", \" \")\n",
    "\n",
    "with open(\"uplift2_step_interpolated_1D.csv\", \"w\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arreglar grilla de archivos uplift y precip\n",
    "#UNICAMENTE CON ASC O TIF\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# Ruta al DEM (puede ser .tif o .asc)\n",
    "dem_path = \"uplift_step_pichilemu_0-0003M.csv\"  # o \"dem.tif\"\n",
    "uplift_path = \"data/uplift_direct.tif\"\n",
    "precip_path = \"data/precip_direct2.tif\"\n",
    "\n",
    "# Abrir DEM como referencia\n",
    "with rasterio.open(dem_path) as dem:\n",
    "    profile = dem.profile\n",
    "    dem_array = dem.read(1)\n",
    "    print(\"✅ DEM cargado con shape:\", dem_array.shape)\n",
    "\n",
    "def raster_to_grid(raster_path, dem_profile):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        data = src.read(\n",
    "            out_shape=(1, dem_profile[\"height\"], dem_profile[\"width\"]),\n",
    "            resampling=rasterio.enums.Resampling.bilinear\n",
    "        )[0]\n",
    "    return data\n",
    "\n",
    "uplift_grid = raster_to_grid(uplift_path, profile)\n",
    "precip_grid = raster_to_grid(precip_path, profile)\n",
    "\n",
    "print(\"✅ Uplift shape:\", uplift_grid.shape)\n",
    "print(\"✅ Precip shape:\", precip_grid.shape)\n",
    "\n",
    "# Guardar en CSV grilla (igual que DEM)\n",
    "    # CSV con coma (útil para inspección)\n",
    "np.savetxt(\"uplift_grilla.csv\", uplift_grid, delimiter=\",\", fmt=\"%.6f\")\n",
    "np.savetxt(\"precip_grilla.csv\", precip_grid, delimiter=\",\", fmt=\"%.6f\")\n",
    "\n",
    "    # TXT con espacios (formato Badlands)\n",
    "np.savetxt(\"uplift_ready.txt\", uplift_grid, delimiter=\" \", fmt=\"%.6f\")\n",
    "np.savetxt(\"precip_ready.txt\", precip_grid, delimiter=\" \", fmt=\"%.6f\")\n",
    "\n",
    "print(\"✅ Archivos listos para Badlands: uplift_ready.txt y precip_ready.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicional para cargar grillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2\n",
      "0  precip         x         y\n",
      "1     1.0  -11119.0  -13495.0\n",
      "2     1.0  -11019.0  -13495.0\n",
      "3     1.0  -10919.0  -13495.0\n",
      "4     1.0  -10819.0  -13495.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Leer uplift.csv detectando separador automáticamente ===\n",
    "uplift_df = pd.read_csv(\"data/precipitation_map_1m.csv\", sep=None, engine=\"python\", header=None)\n",
    "\n",
    "# === Verificar la estructura ===\n",
    "print(uplift_df.head())\n",
    "\n",
    "# === Si tienes tres columnas (x, y, uplift) ===\n",
    "# Extraer solo la columna de uplift\n",
    "uplift_values = uplift_df.iloc[:, 0]  # la última columna\n",
    "\n",
    "# === Guardar CSV solo con valores de uplift, sin encabezado ni índice ===\n",
    "uplift_values.to_csv(\"data/precipitation_map_1m.csv\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Grilla DEM = Grilla uplift y precip\n",
    "#OBTENER UNA TIF UPL/PRECIP CON ASC O TIF\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "# Reabrir el DEM y asignar CRS manualmente\n",
    "dem_path = \"dem_resampled_100m.asc\"\n",
    "with rasterio.open(dem_path, \"r+\") as dem:\n",
    "    dem.crs = CRS.from_epsg(32719)  # Asignamos EPSG:32719 manualmente\n",
    "    print(\"✅ CRS asignado al DEM:\", dem.crs)\n",
    "\n",
    "# === 1. Cargar CSV de uplift ===\n",
    "df = pd.read_csv(\"data/uplift_fixed.csv\")\n",
    "\n",
    "# Asegurar columnas correctas\n",
    "if len(df.columns) == 1:\n",
    "    df = df.iloc[:, 0].str.split(\",\", expand=True)\n",
    "df.columns = [\"x\", \"y\", \"z\"]\n",
    "df = df.apply(pd.to_numeric, errors=\"coerce\").dropna()\n",
    "\n",
    "# === 2. Cargar DEM como referencia ===\n",
    "with rasterio.open(\"dem_resampled_100m.asc\") as dem:\n",
    "    nx, ny = dem.width, dem.height\n",
    "    bounds = dem.bounds\n",
    "    x_min, x_max = bounds.left, bounds.right\n",
    "    y_min, y_max = bounds.bottom, bounds.top\n",
    "    res_x = (x_max - x_min) / nx\n",
    "    res_y = (y_max - y_min) / ny\n",
    "\n",
    "# === 3. Crear matriz vacía ===\n",
    "grid = np.full((ny, nx), -9999.0, dtype=np.float32)\n",
    "\n",
    "# === 4. Asignar valores directamente a la grilla ===\n",
    "for _, row in df.iterrows():\n",
    "    col = int((row[\"x\"] - x_min) / res_x)\n",
    "    row_idx = int((y_max - row[\"y\"]) / res_y)  # invertimos eje Y\n",
    "    if 0 <= row_idx < ny and 0 <= col < nx:\n",
    "        grid[row_idx, col] = row[\"z\"]\n",
    "\n",
    "# === 5. Guardar como GeoTIFF ===\n",
    "transform = from_origin(x_min, y_max, res_x, res_y)\n",
    "with rasterio.open(\n",
    "    \"data/uplift_direct.tif\",\n",
    "    \"w\",\n",
    "    driver=\"GTiff\",\n",
    "    height=ny,\n",
    "    width=nx,\n",
    "    count=1,\n",
    "    dtype=grid.dtype,\n",
    "    crs=\"EPSG:32719\",\n",
    "    transform=transform,\n",
    "    nodata=-9999\n",
    ") as dst:\n",
    "    dst.write(grid, 1)\n",
    "\n",
    "print(\"✅ Archivo generado sin interpolación: uplift_direct.tif\")\n",
    "print(\"📐 Dimensiones:\", grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REORDENAR UPLIFT EN BASE AL CASO DEL CSV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ---- Parámetros / nombres de archivo ----\n",
    "dem_path = \"pichilemu_xyz.csv\"\n",
    "step_path = \"data/stepMapPich4.csv\"\n",
    "\n",
    "# ---- 1) Leer DEM y obtener grilla ----\n",
    "dem = pd.read_csv(dem_path, sep=r\"\\s+\", header=None, names=[\"x\",\"y\",\"elev\"], engine='python')\n",
    "x_unique = np.sort(dem[\"x\"].unique())\n",
    "y_unique = np.sort(dem[\"y\"].unique())\n",
    "ncols = len(x_unique)\n",
    "nrows = len(y_unique)\n",
    "expected = ncols * nrows\n",
    "\n",
    "print(\"DEM: ncols={}, nrows={}, expected cells={}\".format(ncols, nrows, expected))\n",
    "\n",
    "# ---- 2) Leer columna de stepMap robustamente ----\n",
    "def read_single_column(path):\n",
    "    # Intentos variados para leer la columna que contenga los valores\n",
    "    #  - ignora líneas comentadas con '#'\n",
    "    #  - acepta separadores por espacios/tabs o comas\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep=r\"\\s+\", header=None, comment='#', engine='python')\n",
    "        arr = df.values.flatten()\n",
    "    except Exception:\n",
    "        try:\n",
    "            arr = np.loadtxt(path, comments='#')\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"No pude leer {} : {}\".format(path, e))\n",
    "    # keep only finite numeric values\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    arr = arr[np.isfinite(arr)]\n",
    "    return arr\n",
    "\n",
    "values = read_single_column(step_path)\n",
    "print(\"Lectura stepMap: {} valores (sin NaN)\".format(len(values)))\n",
    "\n",
    "# ---- 3) Mapear según el caso ----\n",
    "gx, gy = np.meshgrid(x_unique, y_unique)  # shape (nrows, ncols)\n",
    "\n",
    "def save_grid(u_grid, outname):\n",
    "    df = pd.DataFrame({\n",
    "        \"x\": gx.flatten(),\n",
    "        \"y\": gy.flatten(),\n",
    "        \"uplift\": u_grid.flatten()\n",
    "    })\n",
    "    df.to_csv(outname, index=False)\n",
    "    stats = (df.uplift.min(), df.uplift.mean(), df.uplift.max())\n",
    "    print(\"Guardado: {}  (min,mean,max) = ({:.6g}, {:.6g}, {:.6g})\".format(outname, stats[0], stats[1], stats[2]))\n",
    "\n",
    "# Caso A: la longitud coincide exactamente con la grilla\n",
    "if len(values) == expected:\n",
    "    # Intento 1: orden C (x rápido, y lento) -> típico flatten C-order\n",
    "    grid_C = values.reshape((nrows, ncols), order='C')\n",
    "    save_grid(grid_C, \"uplift_step_orderC.csv\")\n",
    "\n",
    "    # Intento 2: orden F (Fortran, y rápido, x lento) -> alternativa\n",
    "    grid_F = values.reshape((nrows, ncols), order='F')\n",
    "    save_grid(grid_F, \"uplift_step_orderF.csv\")\n",
    "\n",
    "    print(\"He generado dos archivos: 'uplift_step_orderC.csv' y 'uplift_step_orderF.csv'.\")\n",
    "    print(\"Por defecto prueba primero 'uplift_step_orderC.csv' en tu input.xml; si la orientación espacial no coincide, usa la versión 'orderF'.\")\n",
    "\n",
    "# Caso B: un valor por FILA (len == nrows) -> se repite a lo largo de columnas\n",
    "elif len(values) == nrows:\n",
    "    grid = np.tile(values.reshape((nrows,1)), (1, ncols))\n",
    "    save_grid(grid, \"uplift_step_from_rows.csv\")\n",
    "    print(\"Interpreté stepMap como un valor por fila (y).\")\n",
    "\n",
    "# Caso C: un valor por COLUMNA (len == ncols) -> se repite a lo largo de filas\n",
    "elif len(values) == ncols:\n",
    "    grid = np.tile(values.reshape((1,ncols)), (nrows, 1))\n",
    "    save_grid(grid, \"uplift_step_from_cols.csv\")\n",
    "    print(\"Interpreté stepMap como un valor por columna (x).\")\n",
    "\n",
    "# Caso D: un único valor -> rellenar toda la grilla con ese valor\n",
    "elif len(values) == 1:\n",
    "    grid = np.full((nrows, ncols), values[0])\n",
    "    save_grid(grid, \"uplift_step_constant.csv\")\n",
    "    print(\"Step map contiene un único valor: creado uplift constante.\")\n",
    "\n",
    "# Caso E: longitud distinta, pero >1 -> interpolación 1D a lo largo del flattened index\n",
    "elif 1 < len(values) < expected:\n",
    "    # Interpolación simple 1D en el índice flattened\n",
    "    src_idx = np.linspace(0, expected - 1, num=len(values))\n",
    "    tgt_idx = np.arange(expected)\n",
    "    interp_flat = np.interp(tgt_idx, src_idx, values)\n",
    "    grid = interp_flat.reshape((nrows, ncols))\n",
    "    save_grid(grid, \"uplift_16000.csv\")\n",
    "    print(\"Se generó 'uplift_step_interpolated_1D.csv' por interpolación 1D del vector fuente.\")\n",
    "\n",
    "# Caso F: ninguno de los anteriores -> no se puede mapear automáticamente\n",
    "else:\n",
    "    raise RuntimeError(\"No pude mapear automaticamente: len(values)={} no coincide con expected/nrows/ncols = {}/{}/{}.\"\n",
    "                       .format(len(values), expected, nrows, ncols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAR PRECIP CON GRILLA DEM Y VALORES FIJOS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar DEM\n",
    "dem = pd.read_csv(\"xyz.csv\", sep=r\"\\s+\", header=None, names=[\"x\", \"y\", \"elev\"], engine=\"python\")\n",
    "\n",
    "# Extraer coordenadas únicas\n",
    "x_unique = np.sort(dem[\"x\"].unique())\n",
    "y_unique = np.sort(dem[\"y\"].unique())\n",
    "\n",
    "ncols = len(x_unique)\n",
    "nrows = len(y_unique)\n",
    "expected = ncols * nrows\n",
    "\n",
    "precip_value = 1.0\n",
    "precip_grid = np.full((nrows, ncols), precip_value)\n",
    "\n",
    "gx, gy = np.meshgrid(x_unique, y_unique)  # orden C: x rápido, y lento\n",
    "\n",
    "df_precip = pd.DataFrame({\n",
    "    \"x\": gx.flatten(),\n",
    "    \"y\": gy.flatten(),\n",
    "    \"precip\": precip_grid.flatten()\n",
    "})\n",
    "\n",
    "df_precip.to_csv(\"data/precipitation_map_1m.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAR PRECIP CON GRILLA DEM Y VALORES GRADIENTES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === Parámetros espaciales del área de estudio ===\n",
    "xmin, xmax = -11119.0, 27981.0\n",
    "ymin, ymax = -13495.0, 61205.0\n",
    "ncols, nrows = 1761, 1343  # ajustar a tu DEM\n",
    "\n",
    "# === Crear malla espacial ===\n",
    "x = np.linspace(xmin, xmax, ncols)\n",
    "y = np.linspace(ymin, ymax, nrows)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "# === Gradiente de precipitación: costa (Oeste) → interior (Este) ===\n",
    "# 5.0 en la costa, 1.0 en el interior\n",
    "precip = np.interp(xx, [xmin, xmax], [5.0, 1.0])\n",
    "\n",
    "# Añadir una leve variabilidad (±10%) para simular efecto topográfico\n",
    "precip = precip * np.random.normal(1, 0.1, precip.shape)\n",
    "\n",
    "# === Aplanar y exportar sin encabezado ===\n",
    "precip_flat = precip.flatten()\n",
    "pd.DataFrame(precip_flat).to_csv(\"precipitation_map_grad.csv\", index=False, header=False)\n",
    "\n",
    "print(\"✅ Archivo 'precipitation_map_grad.csv' creado con\", len(precip_flat), \"valores entre ~1.0 y 5.0.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
